{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a2c921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f910368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt_to_dict(file_path):\n",
    "    \"\"\"\n",
    "    Reads a text file and converts its contents into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the key-value pairs from the file.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                # Check if the line contains a colon\n",
    "                if ':' in line:\n",
    "                    key, value = line.strip().split(\":\", 1)  # Split by the first colon\n",
    "                    data[key.strip()] = value.strip()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b604ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for i in range(1,20):\n",
    "    res[i] = parse_txt_to_dict(f\"experiments/e{i}/train/results.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09d89784",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, sub_dict in res.items():\n",
    "    if 'sid' in sub_dict:\n",
    "        del sub_dict['sid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e35a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, metrics in res.items():\n",
    "    for metric, value in metrics.items():\n",
    "        # Remove the trailing comma and convert to float\n",
    "        res[key][metric] = float(value.strip(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12b1b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'shd': 1.0,\n",
       "  'fn': 0.0,\n",
       "  'fp': 0.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 0.9370526385102842},\n",
       " 2: {'shd': 3.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 1.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 1.1314296597652729},\n",
       " 3: {'shd': 3.0,\n",
       "  'fn': 0.0,\n",
       "  'fp': 1.0,\n",
       "  'rev': 2.0,\n",
       "  'nll_val': 0.8313778447102383},\n",
       " 4: {'shd': 5.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 2.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 0.8513567092661044},\n",
       " 5: {'shd': 3.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 0.0,\n",
       "  'rev': 2.0,\n",
       "  'nll_val': 0.9880804649793543},\n",
       " 6: {'shd': 4.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 2.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 0.5872324226444693},\n",
       " 7: {'shd': 0.0,\n",
       "  'fn': 0.0,\n",
       "  'fp': 0.0,\n",
       "  'rev': 0.0,\n",
       "  'nll_val': 0.31692471616848},\n",
       " 8: {'shd': 13.0,\n",
       "  'fn': 3.0,\n",
       "  'fp': 7.0,\n",
       "  'rev': 3.0,\n",
       "  'nll_val': 0.8428364766174895},\n",
       " 9: {'shd': 14.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 6.0,\n",
       "  'rev': 6.0,\n",
       "  'nll_val': 0.3171223817977142},\n",
       " 10: {'shd': 2.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 0.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 1.1433606461066543},\n",
       " 11: {'shd': 5.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 1.0,\n",
       "  'rev': 2.0,\n",
       "  'nll_val': 1.013161373866038},\n",
       " 12: {'shd': 5.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 2.0,\n",
       "  'rev': 2.0,\n",
       "  'nll_val': 0.9317846559344476},\n",
       " 13: {'shd': 5.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 2.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 0.7674041213288181},\n",
       " 14: {'shd': 2.0,\n",
       "  'fn': 1.0,\n",
       "  'fp': 0.0,\n",
       "  'rev': 1.0,\n",
       "  'nll_val': 1.005274248041946},\n",
       " 15: {'shd': 4.0,\n",
       "  'fn': 0.0,\n",
       "  'fp': 1.0,\n",
       "  'rev': 3.0,\n",
       "  'nll_val': 0.832575554416734},\n",
       " 16: {'shd': 18.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 8.0,\n",
       "  'rev': 8.0,\n",
       "  'nll_val': 0.48177245930435114},\n",
       " 17: {'shd': 22.0,\n",
       "  'fn': 6.0,\n",
       "  'fp': 8.0,\n",
       "  'rev': 8.0,\n",
       "  'nll_val': 0.6208782074711406},\n",
       " 18: {'shd': 14.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 6.0,\n",
       "  'rev': 6.0,\n",
       "  'nll_val': 0.3326459631217902},\n",
       " 19: {'shd': 12.0,\n",
       "  'fn': 2.0,\n",
       "  'fp': 6.0,\n",
       "  'rev': 4.0,\n",
       "  'nll_val': 0.3163761367890218}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab8a65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\3670790759.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shortened labels for x-axis\n",
    "short_labels = {\n",
    "    1: \"e1: perfect\",\n",
    "    2: \"e2: perfect-unknown\",\n",
    "    3: \"e3: imperfect\",\n",
    "    4: \"e4: perfect\",\n",
    "    5: \"e5: perfect-unknown\",\n",
    "    6: \"e6: imperfect\",\n",
    "    7: \"e7: perfect\",\n",
    "    8: \"e8: perfect-unknown\",\n",
    "    9: \"e9: imperfect\",\n",
    "    10: \"e10: no interventions\",\n",
    "    11: \"e11: removed\",\n",
    "    12: \"e12: no interventions\",\n",
    "    13: \"e13: removed\",\n",
    "    14: \"e14: no interventions\",\n",
    "    15: \"e15: removed\",\n",
    "    16: \"e16: no interventions\",\n",
    "    17: \"e17: perfect-unknown\",\n",
    "    18: \"e18: perfect\",\n",
    "    19: \"e19: perfect longer patience\"\n",
    "}\n",
    "\n",
    "# Grouping cases\n",
    "cases = {\n",
    "    \"Generalization Across Intervention Types\\nCase 1 (Linear Structure)\": [2, 3, 1],\n",
    "    \"Generalization Across Intervention Types\\nCase 2 (Additive Noise Neural Network Structure)\": [5, 6, 4],\n",
    "    \"Generalization Across Intervention Types\\nCase 3 (Nonlinear Non-Additive Noise Structure)\": [8, 9, 7],\n",
    "    \"Identifiability with Varying Numbers of Interventions\\nCase 1 (Perfect - Linear Structure)\": [10, 11, 1],\n",
    "    \"Identifiability with Varying Numbers of Interventions\\nCase 2 (Perfect - Additive Noise Neural Network Structure)\": [12, 13, 4],\n",
    "    \"Identifiability with Varying Numbers of Interventions\\nCase 3 (Imperfect - Nonlinear Non-Additive Noise Structure)\": [14, 15, 3],\n",
    "    \"Synthetic Economic Growth Data Identifiability Tests\": [16, 17, 18, 19]\n",
    "}\n",
    "\n",
    "# Create a directory to save the figures\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Function to clean the case name for filenames (removes parentheses and contents)\n",
    "def clean_case_name(case_name):\n",
    "    return re.sub(r'\\s*\\([^)]*\\)', '', case_name).replace(' ', '_').replace('\\n', '_').replace(':', '')\n",
    "\n",
    "# Function to plot and save SHD, FN, FP, REV together (bar plot)\n",
    "def plot_combined_bars(subset, title, filename):\n",
    "    # Prepare data in long format for seaborn\n",
    "    long_format = subset.melt(id_vars=[\"short_label\"], \n",
    "                              value_vars=[\"shd\", \"fn\", \"fp\", \"rev\"], \n",
    "                              var_name=\"Metric\", \n",
    "                              value_name=\"Value\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(data=long_format, x=\"short_label\", y=\"Value\", hue=\"Metric\", palette=\"viridis\")\n",
    "    \n",
    "    # Add values on top of the bars\n",
    "    for bar in ax.patches:\n",
    "        ax.annotate(\n",
    "            f'{int(bar.get_height())}',  # Show as integer\n",
    "            (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "            ha='center', va='bottom', fontsize=10, color='black'\n",
    "        )\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Experiments\", fontsize=12)\n",
    "    plt.ylabel(\"Value\", fontsize=12)\n",
    "    plt.xticks(rotation=30, ha=\"right\")  # Rotate x-axis labels\n",
    "    plt.legend(title=\"Metrics\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)  # Save as high-resolution image\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "# Function to plot and save NLL values (scatter plot)\n",
    "def plot_nll_scatter(subset, title, filename):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.gca()  # Get current axes\n",
    "    \n",
    "    # Create custom labels with NLL values for the legend\n",
    "    custom_labels = [f\"{row['short_label']} (NLL: {row['nll_val']:.5f})\" for _, row in subset.iterrows()]\n",
    "    \n",
    "    for idx, row in enumerate(subset.iterrows()):\n",
    "        _, data = row\n",
    "        # Plot scatter points\n",
    "        ax.scatter(data['short_label'], data['nll_val'], label=custom_labels[idx], s=100)\n",
    "    \n",
    "    # Formatting\n",
    "    plt.title(f\"NLL Values - {title}\", fontsize=14)\n",
    "    plt.xlabel(\"Experiments\", fontsize=12)\n",
    "    plt.ylabel(\"Negative Log-Likelihood (NLL)\", fontsize=12)\n",
    "    plt.xticks(rotation=30, ha=\"right\")  # Rotate x-axis labels\n",
    "    \n",
    "    # Legend inside the plot\n",
    "    plt.legend(\n",
    "        title=\"Experiments\", \n",
    "        loc='lower left',  # Place in the lower left inside the plot\n",
    "        fontsize=10, \n",
    "        frameon=True,  # Add a border to the legend\n",
    "        fancybox=True,  # Rounded edges\n",
    "        framealpha=0.8  # Transparent background for legend\n",
    "    )\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300)  # Save as high-resolution image\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "# Loop through cases and save both bar and scatter plots\n",
    "for case_name, experiments in cases.items():\n",
    "    # Subset the DataFrame based on the experiments in the case\n",
    "    subset = df[df['experiment'].isin(experiments)]\n",
    "    \n",
    "    # Set the order of the short_label column as specified in the cases dictionary\n",
    "    ordered_labels = [short_labels[exp] for exp in experiments]  # Map experiments to short labels\n",
    "    subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
    "    subset = subset.sort_values('short_label')  # Sort by the specified order\n",
    "    \n",
    "    # Clean case name for filenames\n",
    "    cleaned_name = clean_case_name(case_name)\n",
    "    \n",
    "    # Filenames for saving\n",
    "    bar_filename = f\"{cleaned_name}_bar_plot.png\"\n",
    "    scatter_filename = f\"{cleaned_name}_scatter_plot.png\"\n",
    "    \n",
    "    # Plot and save the figures\n",
    "    plot_combined_bars(subset, title=case_name, filename=bar_filename)\n",
    "    plot_nll_scatter(subset, title=case_name, filename=scatter_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80b3bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table for case: Generalization Across Intervention Types\n",
      "Case 1 (Linear Structure) -> Generalization_Across_Intervention_Types_Case_1.csv\n",
      "Saved table for case: Generalization Across Intervention Types\n",
      "Case 2 (Additive Noise Neural Network Structure) -> Generalization_Across_Intervention_Types_Case_2.csv\n",
      "Saved table for case: Generalization Across Intervention Types\n",
      "Case 3 (Nonlinear Non-Additive Noise Structure) -> Generalization_Across_Intervention_Types_Case_3.csv\n",
      "Saved table for case: Identifiability with Varying Numbers of Interventions\n",
      "Case 1 (Perfect - Linear Structure) -> Identifiability_with_Varying_Numbers_of_Interventions_Case_1.csv\n",
      "Saved table for case: Identifiability with Varying Numbers of Interventions\n",
      "Case 2 (Perfect - Additive Noise Neural Network Structure) -> Identifiability_with_Varying_Numbers_of_Interventions_Case_2.csv\n",
      "Saved table for case: Identifiability with Varying Numbers of Interventions\n",
      "Case 3 (Imperfect - Nonlinear Non-Additive Noise Structure) -> Identifiability_with_Varying_Numbers_of_Interventions_Case_3.csv\n",
      "Saved table for case: Synthetic Economic Growth Data Identifiability Tests -> Synthetic_Economic_Growth_Data_Identifiability_Tests.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
      "C:\\Users\\mert.ekici\\AppData\\Local\\Temp\\ipykernel_21208\\2005925783.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save the tables\n",
    "tables_output_dir = \"results/tables\"\n",
    "os.makedirs(tables_output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Loop through cases and prepare tables\n",
    "for case_name, experiments in cases.items():\n",
    "    # Subset the DataFrame based on the experiments in the case\n",
    "    subset = df[df['experiment'].isin(experiments)]\n",
    "    \n",
    "    # Set the order of the short_label column as specified in the cases dictionary\n",
    "    ordered_labels = [short_labels[exp] for exp in experiments]  # Map experiments to short labels\n",
    "    subset['short_label'] = pd.Categorical(subset['short_label'], categories=ordered_labels, ordered=True)\n",
    "    subset = subset.sort_values('short_label')  # Sort by the specified order\n",
    "\n",
    "    # Select relevant columns and rename them for clarity\n",
    "    table = subset[['short_label', 'fp', 'fn', 'rev', 'shd', 'nll_val']]\n",
    "    table = table.rename(columns={'short_label': 'Experiment', 'nll_val': 'NLL'})  # Rename columns\n",
    "\n",
    "    # Clean case name for filename\n",
    "    cleaned_name = clean_case_name(case_name)\n",
    "\n",
    "    # Save the table as a CSV file\n",
    "    csv_filename = f\"{cleaned_name}.csv\"\n",
    "    table.to_csv(os.path.join(tables_output_dir, csv_filename), index=False)\n",
    "    print(f\"Saved table for case: {case_name} -> {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82df7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: experiments\\e1\\train\\adjacency.png -> results\\adjacency1.png\n",
      "Copied: experiments\\e1\\train\\learning-curves.png -> results\\learning-curves1.png\n",
      "Copied: experiments\\e2\\train\\adjacency.png -> results\\adjacency2.png\n",
      "Copied: experiments\\e2\\train\\learning-curves.png -> results\\learning-curves2.png\n",
      "Copied: experiments\\e2\\interv_w.png -> results\\interv_w2.png\n",
      "Copied: experiments\\e3\\train\\adjacency.png -> results\\adjacency3.png\n",
      "Copied: experiments\\e3\\train\\learning-curves.png -> results\\learning-curves3.png\n",
      "Copied: experiments\\e4\\train\\adjacency.png -> results\\adjacency4.png\n",
      "Copied: experiments\\e4\\train\\learning-curves.png -> results\\learning-curves4.png\n",
      "Copied: experiments\\e5\\train\\adjacency.png -> results\\adjacency5.png\n",
      "Copied: experiments\\e5\\train\\learning-curves.png -> results\\learning-curves5.png\n",
      "Copied: experiments\\e5\\interv_w.png -> results\\interv_w5.png\n",
      "Copied: experiments\\e6\\train\\adjacency.png -> results\\adjacency6.png\n",
      "Copied: experiments\\e6\\train\\learning-curves.png -> results\\learning-curves6.png\n",
      "Copied: experiments\\e7\\train\\adjacency.png -> results\\adjacency7.png\n",
      "Copied: experiments\\e7\\train\\learning-curves.png -> results\\learning-curves7.png\n",
      "Copied: experiments\\e8\\train\\adjacency.png -> results\\adjacency8.png\n",
      "Copied: experiments\\e8\\train\\learning-curves.png -> results\\learning-curves8.png\n",
      "Copied: experiments\\e8\\interv_w.png -> results\\interv_w8.png\n",
      "Copied: experiments\\e9\\train\\adjacency.png -> results\\adjacency9.png\n",
      "Copied: experiments\\e9\\train\\learning-curves.png -> results\\learning-curves9.png\n",
      "Copied: experiments\\e10\\train\\adjacency.png -> results\\adjacency10.png\n",
      "Copied: experiments\\e10\\train\\learning-curves.png -> results\\learning-curves10.png\n",
      "Copied: experiments\\e11\\train\\adjacency.png -> results\\adjacency11.png\n",
      "Copied: experiments\\e11\\train\\learning-curves.png -> results\\learning-curves11.png\n",
      "Copied: experiments\\e12\\train\\adjacency.png -> results\\adjacency12.png\n",
      "Copied: experiments\\e12\\train\\learning-curves.png -> results\\learning-curves12.png\n",
      "Copied: experiments\\e13\\train\\adjacency.png -> results\\adjacency13.png\n",
      "Copied: experiments\\e13\\train\\learning-curves.png -> results\\learning-curves13.png\n",
      "Copied: experiments\\e14\\train\\adjacency.png -> results\\adjacency14.png\n",
      "Copied: experiments\\e14\\train\\learning-curves.png -> results\\learning-curves14.png\n",
      "Copied: experiments\\e15\\train\\adjacency.png -> results\\adjacency15.png\n",
      "Copied: experiments\\e15\\train\\learning-curves.png -> results\\learning-curves15.png\n",
      "Copied: experiments\\e16\\train\\adjacency.png -> results\\adjacency16.png\n",
      "Copied: experiments\\e16\\train\\learning-curves.png -> results\\learning-curves16.png\n",
      "Copied: experiments\\e17\\train\\adjacency.png -> results\\adjacency17.png\n",
      "Copied: experiments\\e17\\train\\learning-curves.png -> results\\learning-curves17.png\n",
      "Copied: experiments\\e17\\interv_w.png -> results\\interv_w17.png\n",
      "Copied: experiments\\e18\\train\\adjacency.png -> results\\adjacency18.png\n",
      "Copied: experiments\\e18\\train\\learning-curves.png -> results\\learning-curves18.png\n",
      "Copied: experiments\\e19\\train\\adjacency.png -> results\\adjacency19.png\n",
      "Copied: experiments\\e19\\train\\learning-curves.png -> results\\learning-curves19.png\n"
     ]
    }
   ],
   "source": [
    "# Define the range of experiments\n",
    "experiment_range = range(1, 20)\n",
    "\n",
    "# Define the directory paths and filenames\n",
    "base_dir = \"experiments\"\n",
    "output_dir = \"results\"  # Directory where the renamed files will be saved\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Iterate through the range of experiments\n",
    "for i in experiment_range:\n",
    "    train_dir = os.path.join(base_dir, f\"e{i}\", \"train\")  # Path to the train directory\n",
    "    experiment_dir = os.path.join(base_dir, f\"e{i}\")  # Path to the experiment directory\n",
    "\n",
    "    # File copying from the train directory\n",
    "    if os.path.exists(train_dir):  # Check if the train directory exists\n",
    "        adjacency_src = os.path.join(train_dir, \"adjacency.png\")\n",
    "        learning_curves_src = os.path.join(train_dir, \"learning-curves.png\")\n",
    "\n",
    "        # Copy adjacency.png with a new name\n",
    "        if os.path.exists(adjacency_src):  # Check if the file exists\n",
    "            adjacency_dst = os.path.join(output_dir, f\"adjacency{i}.png\")\n",
    "            shutil.copy(adjacency_src, adjacency_dst)\n",
    "            print(f\"Copied: {adjacency_src} -> {adjacency_dst}\")\n",
    "\n",
    "        # Copy learning-curves.png with a new name\n",
    "        if os.path.exists(learning_curves_src):  # Check if the file exists\n",
    "            learning_curves_dst = os.path.join(output_dir, f\"learning-curves{i}.png\")\n",
    "            shutil.copy(learning_curves_src, learning_curves_dst)\n",
    "            print(f\"Copied: {learning_curves_src} -> {learning_curves_dst}\")\n",
    "\n",
    "    # Additional copying for specific i values (2, 5, 8, 17)\n",
    "    if i in [2, 5, 8, 17]:\n",
    "        interv_w_src = os.path.join(experiment_dir, \"interv_w.png\")\n",
    "\n",
    "        # Copy interv_w.png with a new name\n",
    "        if os.path.exists(interv_w_src):  # Check if the file exists\n",
    "            interv_w_dst = os.path.join(output_dir, f\"interv_w{i}.png\")\n",
    "            shutil.copy(interv_w_src, interv_w_dst)\n",
    "            print(f\"Copied: {interv_w_src} -> {interv_w_dst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a79c74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Dataset mapping\n",
    "experiment_data = [\n",
    "    (1, \"Generalization Across Intervention Types\", 1, \"data_p10_e10_n10000_linear_struct\"),\n",
    "    (2, \"Generalization Across Intervention Types\", 1, \"data_p10_e10_n10000_linear_struct\"),\n",
    "    (3, \"Generalization Across Intervention Types\", 1, \"data_p10_e10_n10000_linear_brutal_param\"),\n",
    "    (4, \"Generalization Across Intervention Types\", 2, \"data_p10_e10_n10000_nn_struct\"),\n",
    "    (5, \"Generalization Across Intervention Types\", 2, \"data_p10_e10_n10000_nn_struct\"),\n",
    "    (6, \"Generalization Across Intervention Types\", 2, \"data_p10_e10_n10000_nn_brutal_param\"),\n",
    "    (7, \"Generalization Across Intervention Types\", 3, \"data_p10_e10_n10000_nnadd_struct\"),\n",
    "    (8, \"Generalization Across Intervention Types\", 3, \"data_p10_e10_n10000_nnadd_struct\"),\n",
    "    (9, \"Generalization Across Intervention Types\", 3, \"data_p10_e10_n10000_nnadd_brutal_param\"),\n",
    "    (10, \"Identifiability with Varying Numbers of Interventions\", 1, \"data_p10_e10_n10000_linear_struct\"),\n",
    "    (11, \"Identifiability with Varying Numbers of Interventions\", 1, \"data_p10_e10_n10000_linear_struct\"),\n",
    "    (1, \"Identifiability with Varying Numbers of Interventions\", 1, \"data_p10_e10_n10000_linear_struct\"),\n",
    "    (12, \"Identifiability with Varying Numbers of Interventions\", 2, \"data_p10_e10_n10000_nn_struct\"),\n",
    "    (13, \"Identifiability with Varying Numbers of Interventions\", 2, \"data_p10_e10_n10000_nn_struct\"),\n",
    "    (4, \"Identifiability with Varying Numbers of Interventions\", 2, \"data_p10_e10_n10000_nn_struct\"),\n",
    "    (14, \"Identifiability with Varying Numbers of Interventions\", 3, \"data_p10_e10_n10000_linear_brutal_param\"),\n",
    "    (15, \"Identifiability with Varying Numbers of Interventions\", 3, \"data_p10_e10_n10000_linear_brutal_param\"),\n",
    "    (3, \"Identifiability with Varying Numbers of Interventions\", 3, \"data_p10_e10_n10000_linear_brutal_param\"),\n",
    "    (16, \"Synthetic Economic Growth Data Identifiability Tests\", \"Econ Data\", \"data_p10_e20_n10000_macro_policy_scenario\"),\n",
    "    (17, \"Synthetic Economic Growth Data Identifiability Tests\", \"Econ Data\", \"data_p10_e20_n10000_macro_policy_scenario\"),\n",
    "    (18, \"Synthetic Economic Growth Data Identifiability Tests\", \"Econ Data\", \"data_p10_e20_n10000_macro_policy_scenario\"),\n",
    "    (19, \"Synthetic Economic Growth Data Identifiability Tests\", \"Econ Data\", \"data_p10_e20_n10000_macro_policy_scenario\")\n",
    "]\n",
    "\n",
    "# Shortened labels mapping\n",
    "short_labels = {\n",
    "    1: \"e1: perfect\",\n",
    "    2: \"e2: perfect-unknown\",\n",
    "    3: \"e3: imperfect\",\n",
    "    4: \"e4: perfect\",\n",
    "    5: \"e5: perfect-unknown\",\n",
    "    6: \"e6: imperfect\",\n",
    "    7: \"e7: perfect\",\n",
    "    8: \"e8: perfect-unknown\",\n",
    "    9: \"e9: imperfect\",\n",
    "    10: \"e10: no interventions\",\n",
    "    11: \"e11: removed\",\n",
    "    12: \"e12: no interventions\",\n",
    "    13: \"e13: removed\",\n",
    "    14: \"e14: no interventions\",\n",
    "    15: \"e15: removed\",\n",
    "    16: \"e16: no interventions\",\n",
    "    17: \"e17: perfect-unknown\",\n",
    "    18: \"e18: perfect\",\n",
    "    19: \"e19: perfect longer patience\"\n",
    "}\n",
    "\n",
    "# Function to extract dataset details\n",
    "def parse_dataset_name(dataset_name):\n",
    "    match = re.match(r\"data_p(\\d+)_e(\\d+)_n(\\d+)_(.*)\", dataset_name)\n",
    "    if match:\n",
    "        num_nodes = int(match.group(1))\n",
    "        num_edges = int(match.group(2))\n",
    "        num_instances = int(match.group(3))\n",
    "        data_name = match.group(4)\n",
    "        return num_nodes, num_edges, num_instances, data_name\n",
    "    return None, None, None, None\n",
    "\n",
    "# Create a list to hold the rows of the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Build the mapping\n",
    "for experiment_id, experiment, case, dataset_name in experiment_data:\n",
    "    num_nodes, num_edges, num_instances, data_name = parse_dataset_name(dataset_name)\n",
    "    rows.append({\n",
    "        \"Experiment\": f\"e{experiment_id}\",\n",
    "        \"Category\": experiment,\n",
    "        \"Case\": case,\n",
    "        \"Number of Nodes\": num_nodes,\n",
    "        \"Number of Edges\": num_edges,\n",
    "        \"Number of Instances\": num_instances,\n",
    "        \"Dataset Name\": data_name,\n",
    "        \"Independent Variable\": short_labels[experiment_id]  # Add the short label\n",
    "    })\n",
    "\n",
    "# Create the DataFrame\n",
    "experiment_mapping_df = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74d8ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Case</th>\n",
       "      <th>Number of Nodes</th>\n",
       "      <th>Number of Edges</th>\n",
       "      <th>Number of Instances</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Independent Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_struct</td>\n",
       "      <td>e1: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_struct</td>\n",
       "      <td>e2: perfect-unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_brutal_param</td>\n",
       "      <td>e3: imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_struct</td>\n",
       "      <td>e4: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_struct</td>\n",
       "      <td>e5: perfect-unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e6</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_brutal_param</td>\n",
       "      <td>e6: imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e7</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nnadd_struct</td>\n",
       "      <td>e7: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e8</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nnadd_struct</td>\n",
       "      <td>e8: perfect-unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e9</td>\n",
       "      <td>Generalization Across Intervention Types</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nnadd_brutal_param</td>\n",
       "      <td>e9: imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e10</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_struct</td>\n",
       "      <td>e10: no interventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>e11</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_struct</td>\n",
       "      <td>e11: removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e1</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_struct</td>\n",
       "      <td>e1: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e12</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_struct</td>\n",
       "      <td>e12: no interventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e13</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_struct</td>\n",
       "      <td>e13: removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e4</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>nn_struct</td>\n",
       "      <td>e4: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>e14</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_brutal_param</td>\n",
       "      <td>e14: no interventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e15</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_brutal_param</td>\n",
       "      <td>e15: removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e3</td>\n",
       "      <td>Identifiability with Varying Numbers of Interv...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>linear_brutal_param</td>\n",
       "      <td>e3: imperfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>e16</td>\n",
       "      <td>Synthetic Economic Growth Data Identifiability...</td>\n",
       "      <td>Econ Data</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>macro_policy_scenario</td>\n",
       "      <td>e16: no interventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>e17</td>\n",
       "      <td>Synthetic Economic Growth Data Identifiability...</td>\n",
       "      <td>Econ Data</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>macro_policy_scenario</td>\n",
       "      <td>e17: perfect-unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>e18</td>\n",
       "      <td>Synthetic Economic Growth Data Identifiability...</td>\n",
       "      <td>Econ Data</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>macro_policy_scenario</td>\n",
       "      <td>e18: perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>e19</td>\n",
       "      <td>Synthetic Economic Growth Data Identifiability...</td>\n",
       "      <td>Econ Data</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>macro_policy_scenario</td>\n",
       "      <td>e19: perfect longer patience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment                                           Category       Case  \\\n",
       "0          e1           Generalization Across Intervention Types          1   \n",
       "1          e2           Generalization Across Intervention Types          1   \n",
       "2          e3           Generalization Across Intervention Types          1   \n",
       "3          e4           Generalization Across Intervention Types          2   \n",
       "4          e5           Generalization Across Intervention Types          2   \n",
       "5          e6           Generalization Across Intervention Types          2   \n",
       "6          e7           Generalization Across Intervention Types          3   \n",
       "7          e8           Generalization Across Intervention Types          3   \n",
       "8          e9           Generalization Across Intervention Types          3   \n",
       "9         e10  Identifiability with Varying Numbers of Interv...          1   \n",
       "10        e11  Identifiability with Varying Numbers of Interv...          1   \n",
       "11         e1  Identifiability with Varying Numbers of Interv...          1   \n",
       "12        e12  Identifiability with Varying Numbers of Interv...          2   \n",
       "13        e13  Identifiability with Varying Numbers of Interv...          2   \n",
       "14         e4  Identifiability with Varying Numbers of Interv...          2   \n",
       "15        e14  Identifiability with Varying Numbers of Interv...          3   \n",
       "16        e15  Identifiability with Varying Numbers of Interv...          3   \n",
       "17         e3  Identifiability with Varying Numbers of Interv...          3   \n",
       "18        e16  Synthetic Economic Growth Data Identifiability...  Econ Data   \n",
       "19        e17  Synthetic Economic Growth Data Identifiability...  Econ Data   \n",
       "20        e18  Synthetic Economic Growth Data Identifiability...  Econ Data   \n",
       "21        e19  Synthetic Economic Growth Data Identifiability...  Econ Data   \n",
       "\n",
       "    Number of Nodes  Number of Edges  Number of Instances  \\\n",
       "0                10               10                10000   \n",
       "1                10               10                10000   \n",
       "2                10               10                10000   \n",
       "3                10               10                10000   \n",
       "4                10               10                10000   \n",
       "5                10               10                10000   \n",
       "6                10               10                10000   \n",
       "7                10               10                10000   \n",
       "8                10               10                10000   \n",
       "9                10               10                10000   \n",
       "10               10               10                10000   \n",
       "11               10               10                10000   \n",
       "12               10               10                10000   \n",
       "13               10               10                10000   \n",
       "14               10               10                10000   \n",
       "15               10               10                10000   \n",
       "16               10               10                10000   \n",
       "17               10               10                10000   \n",
       "18               10               20                10000   \n",
       "19               10               20                10000   \n",
       "20               10               20                10000   \n",
       "21               10               20                10000   \n",
       "\n",
       "             Dataset Name          Independent Variable  \n",
       "0           linear_struct                   e1: perfect  \n",
       "1           linear_struct           e2: perfect-unknown  \n",
       "2     linear_brutal_param                 e3: imperfect  \n",
       "3               nn_struct                   e4: perfect  \n",
       "4               nn_struct           e5: perfect-unknown  \n",
       "5         nn_brutal_param                 e6: imperfect  \n",
       "6            nnadd_struct                   e7: perfect  \n",
       "7            nnadd_struct           e8: perfect-unknown  \n",
       "8      nnadd_brutal_param                 e9: imperfect  \n",
       "9           linear_struct         e10: no interventions  \n",
       "10          linear_struct                  e11: removed  \n",
       "11          linear_struct                   e1: perfect  \n",
       "12              nn_struct         e12: no interventions  \n",
       "13              nn_struct                  e13: removed  \n",
       "14              nn_struct                   e4: perfect  \n",
       "15    linear_brutal_param         e14: no interventions  \n",
       "16    linear_brutal_param                  e15: removed  \n",
       "17    linear_brutal_param                 e3: imperfect  \n",
       "18  macro_policy_scenario         e16: no interventions  \n",
       "19  macro_policy_scenario          e17: perfect-unknown  \n",
       "20  macro_policy_scenario                  e18: perfect  \n",
       "21  macro_policy_scenario  e19: perfect longer patience  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85370cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment mapping saved to results/tables/experiment_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "output_file = \"results/tables/experiment_mapping.csv\"\n",
    "experiment_mapping_df.to_csv(output_file, index=False)\n",
    "print(f\"Experiment mapping saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29473029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
